{
    "name": "E",
    "learning_rate": 0.001,
    "epochs": 30,
    "dropout": [0.1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
    "batch_size": 132,
    "activation": "tanh",
    "layers": [36, 36, 36, 36, 36, 36, 36]
}