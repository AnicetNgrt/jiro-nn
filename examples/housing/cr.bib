@misc{kchouse,
	month = {6},
	title = {{kc_house_data}},
	year = {2018},
	url = {https://www.kaggle.com/datasets/shivachandel/kc-house-data},
}
@misc{cratesio,
	title = {{crates.io: Rust Package Registry}},
	url = {https://crates.io/},
}
@misc{zerocost,
	author = {Mike-Barber},
	title = {{GitHub - mike-barber/rust-zero-cost-abstractions: Testing out a Zero Cost Abstraction in Rust compared to similar approaches in C# and Java}},
	url = {https://github.com/mike-barber/rust-zero-cost-abstractions},
}
@article{randomforests,
	author = {Breiman, Leo},
	journal = {Machine Learning},
	month = {10},
	number = {1},
	pages = {5--32},
	publisher = {Springer Science+Business Media},
	title = {{Random Forests}},
	volume = {45},
	year = {2001},
	doi = {10.1023/a:1010933404324},
	url = {https://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf},
}
@misc{importance,
	author = {Fisher, Aaron},
	month = {1},
	title = {{All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously}},
	year = {2018},
	url = {https://arxiv.org/abs/1801.01489},
}
@inproceedings{relu,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = {12},
	pages = {1097--1105},
	title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
	volume = {25},
	year = {2012},
	url = {http://books.nips.cc/papers/files/nips25/NIPS2012_0534.pdf},
}
@article{relu-mlm,
	author = {Brownlee, Jason},
	journal = {MachineLearningMastery.com},
	month = {8},
	title = {{A Gentle Introduction to the Rectified Linear Unit (ReLU)}},
	year = {2020},
	url = {https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/},
}
@misc{gdtechniques,
	author = {Ruder, Sebastian},
	month = {9},
	title = {{An overview of gradient descent optimization algorithms}},
	year = {2016},
	url = {https://arxiv.org/abs/1609.04747},
}
@misc{mit-intro,
	author = {Alexander Amini},
	month = {3},
	title = {{MIT Introduction to Deep Learning | 6.S191}},
	year = {2023},
	url = {https://www.youtube.com/watch?v=QDX-1M5Nj7s},
}
@article{k-fold-mlm,
	author = {Brownlee, Jason},
	journal = {MachineLearningMastery.com},
	month = {8},
	title = {{A Gentle Introduction to k-fold Cross-Validation}},
	year = {2020},
	url = {https://machinelearningmastery.com/k-fold-cross-validation/},
}
@article{minmax,
	author = {Aksu, Gökhan and Güzeller, Cem Oktay and Eser, Mehmet},
	journal = {International Journal of Assessment Tools in Education},
	month = {7},
	pages = {170--192},
	publisher = {International Journal of Assessment Tools in Education},
	title = {{The Effect of the Normalization Method Used in Different Sample Sizes on the Success of Artificial Neural Network Model}},
	year = {2019},
	doi = {10.21449/ijate.479404},
	url = {https://dergipark.org.tr/en/download/article-file/682739},
}
@article{feature-scaling,
	author = {Godoy, Daniel},
	month = {9},
	title = {{Gradient Descent, the Learning Rate, and the importance of Feature Scaling}},
	year = {2022},
	url = {https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1},
}
@article{workflow,
	author = {Chavesfm},
	journal = {Kaggle},
	month = {1},
	title = {{DNN House Price R²=0.88}},
	year = {2021},
	url = {https://www.kaggle.com/code/chavesfm/dnn-house-price-r-0-88/notebook},
}
@article{normalize-mlm,
	author = {Chng, Zhe Ming},
	journal = {MachineLearningMastery.com},
	month = {6},
	title = {{Using Normalization Layers to Improve Deep Learning Models}},
	year = {2022},
	url = {https://machinelearningmastery.com/using-normalization-layers-to-improve-deep-learning-models/},
}
@inproceedings{minibatch,
	author = {Cotter, Andrew and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
	month = {12},
	pages = {1647--1655},
	title = {{Better Mini-Batch Algorithms via Accelerated Gradient Methods}},
	volume = {24},
	year = {2011},
	url = {https://papers.nips.cc/paper/2011/file/b55ec28c52d5f6205684a473a2193564-Paper.pdf},
}
@inproceedings{glorot,
	author = {Glorot, Xavier and Bengio, Yoshua},
	month = {3},
	pages = {249--256},
	title = {{Understanding the difficulty of training deep feedforward neural networks}},
	year = {2010},
	url = {https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
}
@misc{dropouts2,
	author = {Hinton, Geoffrey E.},
	month = {7},
	title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
	year = {2012},
	url = {https://arxiv.org/abs/1207.0580},
}
@misc{arewelearning,
	title = {{Index}},
	url = {https://www.arewelearningyet.com/},
}
@misc{tukeys,
	title = {{InterQuartile Range (IQR)}},
	url = {https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_summarizingdata/bs704_summarizingdata7.html},
}
@misc{adam,
	author = {Kingma, Diederik P.},
	month = {12},
	title = {{Adam: A Method for Stochastic Optimization}},
	year = {2014},
	url = {https://arxiv.org/abs/1412.6980},
}
@article{lrdecay,
	author = {Lau, Suki},
	month = {6},
	title = {{Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning}},
	year = {2018},
	url = {https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1},
}
@misc{rsquared,
	title = {{Numeracy, Maths and Statistics - Academic Skills Kit}},
	url = {https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html#Interpretation%20of%20the%20$R^2$%20value},
}
@inproceedings{betteradam,
	author = {Reddi, Sashank J. and Kale, Satyen and Kumar, Sanjiv},
	month = {2},
	title = {{On the Convergence of Adam and Beyond}},
	year = {2018},
	url = {https://arxiv.org/pdf/1904.09237},
}
@misc{layer-specific-lr,
	author = {Singh, Bharat},
	month = {10},
	title = {{Layer-Specific Adaptive Learning Rates for Deep Networks}},
	year = {2015},
	url = {https://arxiv.org/abs/1510.04609},
}
@misc{batch-size,
	author = {Smith, Samuel L.},
	month = {11},
	title = {{Don't Decay the Learning Rate, Increase the Batch Size}},
	year = {2017},
	url = {https://arxiv.org/abs/1711.00489},
}
@article{dropouts,
	author = {Srivastava, Nitish and Hinton, Geoffrey E. and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal = {Journal of Machine Learning Research},
	month = {1},
	title = {{Dropout: a simple way to prevent neural networks from overfitting}},
	year = {2014},
	url = {https://jmlr.csail.mit.edu/papers/volume15/srivastava14a/srivastava14a.pdf},
}
@misc{inversetimedecay,
	author = {Tensorflow},
	title = {{tf.keras.optimizers.schedules.InverseTimeDecay}},
	url = {https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay},
}
@article{regularization,
	author = {Tewari, Ujwal},
	month = {1},
	title = {{Regularization — Understanding L1 and L2 regularization for Deep Learning}},
	year = {2022},
	url = {https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf},
}
@article{fromscratch,
	author = {Aflak, Omar},
	month = {5},
	title = {{Neural Network from scratch in Python - Towards Data Science}},
	year = {2021},
	url = {https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65},
}
@misc{wgpu,
	title = {{wgpu: portable graphics library for Rust}},
	url = {https://wgpu.rs/},
}